# Day 13: Visualizing Deep Learning with TensorBoard

Author: Muntasir

## Introduction to TensorBoard

TensorBoard is a powerful visualization toolkit that comes with TensorFlow. It provides a suite of web applications for inspecting and understanding your TensorFlow runs and graphs. TensorBoard makes it easy to track and visualize metrics like loss and accuracy, view model graphs, analyze model weights and biases, and much more.

## Key Features of TensorBoard

1. **Scalars**: Visualize scalar metrics like loss and accuracy over time
2. **Graphs**: View the computational graph of your model
3. **Histograms**: Monitor the distribution of weights and biases
4. **Images**: View sample images and their predictions
5. **Projector**: Visualize high-dimensional data in 3D

## How TensorBoard Works

TensorBoard reads event files that contain summary data written by TensorFlow. These files are generated by the TensorBoard callback during model training. The callback logs various metrics and model information at specified intervals, which TensorBoard then visualizes in its web interface.

## Running the MNIST CNN with TensorBoard

### Prerequisites
- Python 3.x
- TensorFlow 2.x
- Matplotlib
- NumPy

### Step-by-Step Instructions

1. **Run the Training Script**:
   ```bash
   python mnist_cnn_tensorboard.py
   ```
   This will:
   - Train the CNN model on MNIST dataset
   - Generate TensorBoard logs in the `logs` directory
   - Save training plots in the `plots` directory
   - Save the trained model as `mnist_cnn_model.h5`

2. **Launch TensorBoard**:
   ```bash
   tensorboard --logdir logs
   ```
   This will start the TensorBoard server, typically at `http://localhost:6006`

3. **View Visualizations**:
   - Open your web browser and navigate to `http://localhost:6006`
   - Explore different tabs:
     - SCALARS: View training/validation accuracy and loss
     - GRAPHS: Examine the model architecture
     - HISTOGRAMS: Monitor weight distributions
     - IMAGES: View sample predictions

## Understanding the TensorBoard Callback

In our implementation, we use the TensorBoard callback with the following configuration:

```python
tensorboard_callback = tf.keras.callbacks.TensorBoard(
    log_dir=log_dir,          # Directory to store logs
    histogram_freq=1,         # Log histograms every epoch
    write_graph=True,         # Log the model graph
    write_images=True,        # Log sample images
    update_freq='epoch',      # Log after each epoch
    profile_batch=2           # Profile the second batch
)
```

## What's Being Logged

1. **Training Metrics**:
   - Loss
   - Accuracy
   - Validation loss
   - Validation accuracy

2. **Model Information**:
   - Model graph
   - Layer weights and biases
   - Sample predictions

3. **Training Plots**:
   - Accuracy curves
   - Loss curves
   (Saved in `plots/training_history.png`)

## Next Steps

1. **Custom Scalars**:
   - Create custom scalar plots
   - Compare multiple metrics
   - Add custom metrics

2. **Embedding Projector**:
   - Visualize high-dimensional data
   - Analyze feature representations
   - Perform dimensionality reduction

3. **Hyperparameter Tuning**:
   - Log different model configurations
   - Compare training runs
   - Track hyperparameter effects

4. **Advanced Visualizations**:
   - Add confusion matrices
   - Visualize attention maps
   - Track gradient flow

## Troubleshooting

1. **TensorBoard Not Starting**:
   - Ensure the log directory exists
   - Check if another process is using port 6006
   - Verify TensorFlow installation

2. **No Data Showing**:
   - Confirm logs are being written
   - Check log directory path
   - Verify callback configuration

3. **Memory Issues**:
   - Reduce logging frequency
   - Limit number of samples
   - Adjust batch size

## Conclusion

TensorBoard is an essential tool for deep learning development, providing insights into model training and performance. By using TensorBoard effectively, you can:
- Monitor training progress
- Debug model issues
- Optimize hyperparameters
- Understand model behavior

Remember to regularly check TensorBoard during training to catch potential issues early and ensure your model is learning as expected. 